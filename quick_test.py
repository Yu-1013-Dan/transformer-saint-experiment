#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ä½¿ç”¨è™šæ‹Ÿæ•°æ®æµ‹è¯•SAINTæ¨¡å‹
"""

import torch
import pandas as pd
import numpy as np
from torch.utils.data import DataLoader

def quick_test():
    """å¿«é€Ÿæµ‹è¯•SAINTæ¨¡å‹çš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•...")
    
    try:
        # 1. æµ‹è¯•å¯¼å…¥
        print("\n1. æµ‹è¯•å¯¼å…¥...")
        from saint.data_utils import data_prep_custom, DataSetCatCon
        from saint.models import SAINT
        from saint.augmentations import embed_data_mask
        import torch.optim as optim
        from torch import nn
        print("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # 2. åˆ›å»ºè™šæ‹Ÿæ•°æ®
        print("\n2. åˆ›å»ºè™šæ‹Ÿæ•°æ®...")
        num_samples = 1000
        
        # æ¨¡æ‹Ÿæ™ºèƒ½å®¶å±…è®¾å¤‡æ•°æ®
        np.random.seed(42)
        data = {
            # åˆ†ç±»ç‰¹å¾
            'protocol': np.random.choice(['TCP', 'UDP', 'ICMP'], num_samples),
            'port': np.random.choice([80, 443, 22, 21, 25, 53, 8080], num_samples),
            'device_type': np.random.choice(['Camera', 'Light', 'Speaker', 'Thermostat'], num_samples),
            
            # æ•°å€¼ç‰¹å¾
            'packet_size': np.random.exponential(500, num_samples),
            'duration': np.random.exponential(10, num_samples),
            'byte_count': np.random.exponential(1000, num_samples),
        }
        
        # ç›®æ ‡å˜é‡ - è®¾å¤‡ç±»åˆ«
        target_mapping = {'Camera': 0, 'Light': 1, 'Speaker': 2, 'Thermostat': 3}
        data['device_category'] = [target_mapping[dt] for dt in data['device_type']]
        
        df = pd.DataFrame(data)
        
        cat_cols = ['protocol', 'port', 'device_type']
        con_cols = ['packet_size', 'duration', 'byte_count']
        
        print(f"âœ“ åˆ›å»ºè™šæ‹Ÿæ•°æ®: {df.shape}")
        print(f"åˆ†ç±»ç‰¹å¾: {cat_cols}")
        print(f"æ•°å€¼ç‰¹å¾: {con_cols}")
        
        # 3. æ•°æ®é¢„å¤„ç†
        print("\n3. æ•°æ®é¢„å¤„ç†...")
        cat_dims, cat_idxs, con_idxs, X_train, y_train, X_valid, y_valid, X_test, y_test, train_mean, train_std, bins = data_prep_custom(
            X=df[cat_cols + con_cols],
            y=df['device_category'],
            cat_cols=cat_cols,
            con_cols=con_cols,
            task='multiclass'
        )
        
        print(f"âœ“ æ•°æ®é¢„å¤„ç†å®Œæˆ")
        print(f"ç±»åˆ«ç»´åº¦: {cat_dims}")
        print(f"è®­ç»ƒé›†å¤§å°: {X_train['data'].shape[0]}")
        
        # 4. åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("\n4. åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        continuous_mean_std = np.array([train_mean, train_std]).astype(np.float32)
        
        train_ds = DataSetCatCon(X_train, y_train, cat_idxs, task='clf', continuous_mean_std=continuous_mean_std)
        trainloader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0)
        
        valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs, task='clf', continuous_mean_std=continuous_mean_std)
        validloader = DataLoader(valid_ds, batch_size=64, shuffle=False, num_workers=0)
        
        print(f"âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # 5. åˆå§‹åŒ–æ¨¡å‹
        print("\n5. åˆå§‹åŒ–æ¨¡å‹...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        model = SAINT(
            categories=tuple(cat_dims),
            num_continuous=len(con_cols),
            dim=32,
            depth=3,
            heads=4,
            categorical_embedding_type='ft',
            numerical_embedding_type='ple',
            bins=bins,
            attentiontype='col',
            y_dim=4  # 4ä¸ªè®¾å¤‡ç±»åˆ«
        )
        model.to(device)
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œå‚æ•°é‡: {total_params:,}")
        
        # 6. å¿«é€Ÿè®­ç»ƒæµ‹è¯•
        print("\n6. å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆ3ä¸ªepochï¼‰...")
        optimizer = optim.AdamW(model.parameters(), lr=0.0001)  # é™ä½å­¦ä¹ ç‡
        criterion = nn.CrossEntropyLoss()
        
        # Enable anomaly detection for debugging
        torch.autograd.set_detect_anomaly(True)
        
        for epoch in range(3):
            model.train()
            epoch_loss = 0.0
            num_batches = 0
            
            for i, data in enumerate(trainloader):
                if i >= 3:  # åªè®­ç»ƒå‰3ä¸ªæ‰¹æ¬¡
                    break
                
                optimizer.zero_grad()
                x_categ, x_cont, y_gts, cat_mask, con_mask = [d.to(device) for d in data]
                
                # å‰å‘ä¼ æ’­
                _, x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)
                reps = model.transformer(x_categ_enc, x_cont_enc)
                y_reps = reps[:, 0, :]
                y_outs = model.mlpfory(y_reps)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
                if torch.isnan(y_outs).any() or torch.isinf(y_outs).any():
                    print(f"è­¦å‘Š: è¾“å‡ºåŒ…å«NaNæˆ–Infå€¼")
                    continue
                
                loss = criterion(y_outs, y_gts.squeeze())
                
                # æ£€æŸ¥lossæ˜¯å¦ä¸ºNaN
                if torch.isnan(loss):
                    print(f"è­¦å‘Š: æŸå¤±ä¸ºNaNï¼Œè·³è¿‡è¿™ä¸ªæ‰¹æ¬¡")
                    continue
                
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
            
            avg_loss = epoch_loss / num_batches if num_batches > 0 else 0
            print(f"  Epoch {epoch+1}: æŸå¤± = {avg_loss:.4f}")
        
        # 7. éªŒè¯æµ‹è¯•
        print("\n7. éªŒè¯æµ‹è¯•...")
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for i, data in enumerate(validloader):
                if i >= 2:  # åªæµ‹è¯•å‰2ä¸ªæ‰¹æ¬¡
                    break
                
                x_categ, x_cont, y_gts, cat_mask, con_mask = [d.to(device) for d in data]
                
                _, x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask, model)
                reps = model.transformer(x_categ_enc, x_cont_enc)
                y_reps = reps[:, 0, :]
                y_outs = model.mlpfory(y_reps)
                
                _, predicted = torch.max(y_outs.data, 1)
                total += y_gts.size(0)
                correct += (predicted == y_gts.squeeze()).sum().item()
        
        accuracy = 100 * correct / total if total > 0 else 0
        print(f"âœ“ éªŒè¯å‡†ç¡®ç‡: {accuracy:.2f}%")
        
        print("\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼æ‰€æœ‰åŸºæœ¬åŠŸèƒ½æ­£å¸¸")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = quick_test()
    if success:
        print("\nâœ… é¡¹ç›®åŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œå¯ä»¥è¿›è¡Œå®Œæ•´æµ‹è¯•æˆ–è®­ç»ƒ")
    else:
        print("\nâŒ é¡¹ç›®å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯") 