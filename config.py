"""
SAINTé¡¹ç›®é…ç½®æ–‡ä»¶
ç»Ÿä¸€ç®¡ç†æ•°æ®è·¯å¾„ã€æ¨¡å‹å‚æ•°å’Œè®­ç»ƒé…ç½®
"""
import os

# === æ•°æ®è·¯å¾„é…ç½® ===
DATA_ROOT = "/mnt/d/æ•°æ®é›†/CIC"  # ç”¨æˆ·éœ€è¦æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
PROCESSED_DATA_DIR = "processed_data"

# CSVæ–‡ä»¶åˆ—è¡¨ (ç”¨æˆ·éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´)
CSV_FILES = [
    os.path.join(DATA_ROOT, "BenignTraffic.csv"),
    os.path.join(DATA_ROOT, "BenignTraffic1.csv"),
    os.path.join(DATA_ROOT, "BenignTraffic2.csv"),
    os.path.join(DATA_ROOT, "BenignTraffic3.csv")
]

# === æ•°æ®é¢„å¤„ç†é…ç½® ===
TARGET_COLUMN = 'target_device_type'
RAW_DEVICE_NAME_SOURCE_COLUMN = 'device_mac'

# å¼€å‘æ¨¡å¼ï¼šä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿæµ‹è¯•
DEVELOPMENT_MODE = True
DEV_NROWS_PER_FILE = 50000  # æ¯ä¸ªæ–‡ä»¶åªè¯»å–5ä¸‡è¡Œç”¨äºå¿«é€Ÿå¼€å‘

# === æ¨¡å‹é…ç½® ===
MODEL_CONFIG = {
    'embedding_size': 32,
    'transformer_depth': 6,
    'attention_heads': 8,
    'attention_dropout': 0.1,
    'ff_dropout': 0.1,
    'categorical_embedding_type': 'saint',  # 'saint' or 'ft'
    'numerical_embedding_type': 'mlp',      # 'mlp' or 'ple'
    'attentiontype': 'colrow',              # 'col', 'row', 'colrow'
    'final_mlp_style': 'common'             # 'common' or 'sep'
}

# === è®­ç»ƒé…ç½® ===
TRAINING_CONFIG = {
    'epochs': 100,
    'batch_size': 256,
    'lr': 0.0001,
    'optimizer': 'AdamW',  # 'AdamW', 'Adam', 'SGD'
    'scheduler': 'cosine', # 'cosine', 'linear'
    'device': 'cuda' if os.system('nvidia-smi') == 0 else 'cpu'
}

# === æ€§èƒ½ä¼˜åŒ–é…ç½® ===
PERFORMANCE_CONFIG = {
    'num_workers': 4,           # DataLoaderå·¥ä½œè¿›ç¨‹æ•°
    'pin_memory': True,         # åŠ é€ŸGPUæ•°æ®ä¼ è¾“
    'mixed_precision': True,    # æ··åˆç²¾åº¦è®­ç»ƒ
    'gradient_accumulation_steps': 1,  # æ¢¯åº¦ç´¯ç§¯
    'max_grad_norm': 1.0       # æ¢¯åº¦è£å‰ª
}

# === è‡ªåŠ¨æ€§èƒ½è°ƒæ•´ ===
def auto_adjust_config(num_features, num_samples):
    """æ ¹æ®æ•°æ®è§„æ¨¡è‡ªåŠ¨è°ƒæ•´é…ç½®"""
    config = MODEL_CONFIG.copy()
    
    # ç‰¹å¾æ•°é‡è¿‡å¤šæ—¶çš„è°ƒæ•´
    if num_features > 100:
        config['embedding_size'] = min(16, config['embedding_size'])
        TRAINING_CONFIG['batch_size'] = min(128, TRAINING_CONFIG['batch_size'])
        print(f"ğŸ”§ æ£€æµ‹åˆ°é«˜ç»´ç‰¹å¾({num_features})ï¼Œè‡ªåŠ¨è°ƒæ•´åµŒå…¥ç»´åº¦ä¸º{config['embedding_size']}")
    
    # æ ·æœ¬æ•°é‡è¾ƒå°‘æ—¶çš„è°ƒæ•´
    if num_samples < 100000:
        config['transformer_depth'] = min(3, config['transformer_depth'])
        config['attention_heads'] = min(4, config['attention_heads'])
        print(f"ğŸ”§ æ£€æµ‹åˆ°å°æ•°æ®é›†({num_samples})ï¼Œè‡ªåŠ¨è°ƒæ•´æ¨¡å‹æ·±åº¦ä¸º{config['transformer_depth']}")
    
    # è¡Œæ³¨æ„åŠ›ç‰¹æ®Šè°ƒæ•´
    if config['attentiontype'] in ['row', 'colrow']:
        config['transformer_depth'] = 1
        config['attention_dropout'] = 0.8
        config['ff_dropout'] = 0.8
        print(f"ğŸ”§ ä½¿ç”¨{config['attentiontype']}æ³¨æ„åŠ›ï¼Œåº”ç”¨ç‰¹æ®Šé…ç½®")
    
    return config 