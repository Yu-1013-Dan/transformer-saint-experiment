#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CIC IoT 2024 ç‰¹å¾åˆ†ç±»å’Œç´¢å¼•è¡¨ç”Ÿæˆæ¨¡å—
æ ¹æ®ç”¨æˆ·å…·ä½“è¦æ±‚è¿›è¡Œç²¾ç¡®ç‰¹å¾åˆ†ç±»
"""

import pandas as pd
import numpy as np
import os
import json
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class CICIoTFeatureClassifier:
    """CIC IoTæ•°æ®é›†ç‰¹å¾åˆ†ç±»å™¨ - ç”¨æˆ·å®šåˆ¶ç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç‰¹å¾åˆ†ç±»å™¨ - æ ¹æ®ç”¨æˆ·å…·ä½“è¦æ±‚"""
        
        # æ ‡ç­¾åˆ—
        self.label_columns = ['device_mac']
        
        # éœ€è¦æ’é™¤çš„åˆ—ï¼ˆç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼‰
        self.excluded_columns = [
            'stream', 'src_mac', 'dst_mac', 'src_ip', 'dst_ip', 
            'Label 1 for DI', 'Label 2 for AD'
        ]
        
        # ç”¨æˆ·ç²¾ç¡®æŒ‡å®šçš„ç±»åˆ«ç‰¹å¾åˆ—è¡¨
        self.user_defined_categorical_list = [
            'src_port', 'dst_port', 'port_class_dst', 'l4_tcp', 'l4_udp',
            'handshake_version', 'handshake_ciphersuites', 'tls_server',
            'http_request_method', 'http_host', 'http_response_code', 'user_agent',
            'dns_server', 'dns_query_type', 'eth_src_oui', 'eth_dst_oui',
            'highest_layer', 'http_uri', 'http_content_type', 'icmp_type', 
            'icmp_checksum_status'
        ]
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        self.user_defined_categorical = {feature: 'ç±»åˆ«å‹' for feature in self.user_defined_categorical_list}
        
        # ç”¨æˆ·ç²¾ç¡®æŒ‡å®šçš„æ•°å€¼ç‰¹å¾åˆ—è¡¨
        self.user_defined_numerical_list = [
            'inter_arrival_time', 'time_since_previously_displayed_frame', 'ttl', 'eth_size',
            'tcp_window_size', 'payload_entropy', 'handshake_cipher_suites_length',
            'handshake_extensions_length', 'handshake_sig_hash_alg_len', 'dns_len_qry',
            'dns_interval', 'dns_len_ans', 'payload_length', 'http_content_len',
            'icmp_data_size', 'jitter', 'stream_1_count', 'stream_1_mean', 'stream_1_var',
            'src_ip_1_count', 'src_ip_1_mean', 'src_ip_1_var', 'src_ip_mac_1_count',
            'src_ip_mac_1_mean', 'src_ip_mac_1_var', 'channel_1_count', 'channel_1_mean',
            'channel_1_var', 'stream_jitter_1_sum', 'stream_jitter_1_mean',
            'stream_jitter_1_var', 'stream_5_count', 'stream_5_mean', 'stream_5_var',
            'src_ip_5_count', 'src_ip_5_mean', 'src_ip_5_var', 'src_ip_mac_5_count',
            'src_ip_mac_5_mean', 'src_ip_mac_5_var', 'channel_5_count', 'channel_5_mean',
            'channel_5_var', 'stream_jitter_5_sum', 'stream_jitter_5_mean',
            'stream_jitter_5_var', 'stream_10_count', 'stream_10_mean', 'stream_10_var',
            'src_ip_10_count', 'src_ip_10_mean', 'src_ip_10_var', 'src_ip_mac_10_count',
            'src_ip_mac_10_mean', 'src_ip_mac_10_var', 'channel_10_count',
            'channel_10_mean', 'channel_10_var', 'stream_jitter_10_sum',
            'stream_jitter_10_mean', 'stream_jitter_10_var', 'stream_30_count',
            'stream_30_mean', 'stream_30_var', 'src_ip_30_count', 'src_ip_30_mean',
            'src_ip_30_var', 'src_ip_mac_30_count', 'src_ip_mac_30_mean',
            'src_ip_mac_30_var', 'channel_30_count', 'channel_30_mean',
            'channel_30_var', 'stream_jitter_30_sum', 'stream_jitter_30_mean',
            'stream_jitter_30_var', 'stream_60_count', 'stream_60_mean', 'stream_60_var',
            'src_ip_60_count', 'src_ip_60_mean', 'src_ip_60_var', 'src_ip_mac_60_count',
            'src_ip_mac_60_mean', 'src_ip_mac_60_var', 'channel_60_count',
            'channel_60_mean', 'channel_60_var', 'stream_jitter_60_sum',
            'stream_jitter_60_mean', 'stream_jitter_60_var', 'ntp_interval',
            'most_freq_spot', 'min_et', 'q1', 'min_e', 'var_e', 'q1_e', 'sum_p',
            'min_p', 'max_p', 'med_p', 'average_p', 'var_p', 'q3_p', 'q1_p', 'iqr_p',
            'l3_ip_dst_count'
        ]
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        self.user_defined_numerical = {feature: 'æ•°å€¼å‹' for feature in self.user_defined_numerical_list}
        

        
        # é«˜åŸºæ•°ç‰¹å¾ï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
        self.high_cardinality_features = [
            'handshake_ciphersuites', 'tls_server', 'http_host', 
            'user_agent', 'dns_server', 'http_uri'
        ]
    
    def classify_features_automatically(self, df: pd.DataFrame) -> Dict[str, List]:
        """æ ¹æ®ç”¨æˆ·å…·ä½“è¦æ±‚è¿›è¡Œè‡ªåŠ¨ç‰¹å¾åˆ†ç±»"""
        print("ğŸ·ï¸  æ ¹æ®ç”¨æˆ·è¦æ±‚è¿›è¡Œç²¾ç¡®ç‰¹å¾åˆ†ç±»...")
        
        all_columns = list(df.columns)
        classification = {
            'label_columns': [],
            'identifier_columns': [],
            'categorical_features': [],
            'numerical_features': [],
            'high_cardinality_features': [],
            'text_features': [],
            'excluded_features': []
        }
        
        for col in all_columns:
            col_lower = col.lower()
            
            # 1. æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡ç­¾åˆ—
            if col in self.label_columns:
                classification['label_columns'].append(col)
                continue
            
            # 2. æ£€æŸ¥æ˜¯å¦ä¸ºæ’é™¤åˆ—
            if col in self.excluded_columns:
                classification['excluded_features'].append(col)
                continue
            
            # 3. æ£€æŸ¥ç”¨æˆ·ç²¾ç¡®å®šä¹‰çš„ç±»åˆ«ç‰¹å¾
            if col in self.user_defined_categorical_list:
                classification['categorical_features'].append(col)
                # æ£€æŸ¥æ˜¯å¦ä¸ºé«˜åŸºæ•°ç‰¹å¾
                if col in self.high_cardinality_features:
                    classification['high_cardinality_features'].append(col)
                continue
            
            # 4. æ£€æŸ¥ç”¨æˆ·ç²¾ç¡®å®šä¹‰çš„æ•°å€¼ç‰¹å¾
            if col in self.user_defined_numerical_list:
                classification['numerical_features'].append(col)
                continue
            
            # 5. å¯¹äºç”¨æˆ·æœªæ˜ç¡®æŒ‡å®šçš„ç‰¹å¾ï¼Œæ’é™¤å®ƒä»¬
            classification['excluded_features'].append(col)
        
        # æ‰“å°è¯¦ç»†åˆ†ç±»ç»“æœ
        print(f"\nğŸ“Š ç”¨æˆ·è¦æ±‚çš„ç‰¹å¾åˆ†ç±»ç»“æœ:")
        print(f"   æ ‡ç­¾åˆ— ({len(classification['label_columns'])}): {classification['label_columns']}")
        print(f"   æ’é™¤åˆ— ({len(classification['excluded_features'])}): {classification['excluded_features'][:10]}{'...' if len(classification['excluded_features']) > 10 else ''}")
        print(f"   ç±»åˆ«ç‰¹å¾ ({len(classification['categorical_features'])}): {classification['categorical_features'][:10]}{'...' if len(classification['categorical_features']) > 10 else ''}")
        print(f"   æ•°å€¼ç‰¹å¾ ({len(classification['numerical_features'])}): {classification['numerical_features'][:10]}{'...' if len(classification['numerical_features']) > 10 else ''}")
        print(f"   é«˜åŸºæ•°ç‰¹å¾ ({len(classification['high_cardinality_features'])}): {classification['high_cardinality_features']}")
        
        total_features = len(classification['categorical_features']) + len(classification['numerical_features'])
        print(f"   æ€»æœ‰æ•ˆç‰¹å¾: {total_features} ä¸ª")
        print(f"   æœŸæœ›ç‰¹å¾æ€»æ•°: {len(self.user_defined_categorical_list) + len(self.user_defined_numerical_list)} ä¸ª")
        
        return classification
    
    def analyze_dataframe_structure(self, df: pd.DataFrame) -> Dict:
        """åˆ†æDataFrameçš„ç»“æ„å’Œç‰¹å¾ç±»å‹"""
        print("ğŸ” å¼€å§‹åˆ†æDataFrameç»“æ„...")
        
        structure_info = {
            'total_columns': len(df.columns),
            'total_rows': len(df),
            'column_names': list(df.columns),
            'dtypes': df.dtypes.to_dict(),
            'missing_values': df.isnull().sum().to_dict(),
            'unique_counts': {},
            'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024**2)
        }
        
        # è®¡ç®—å”¯ä¸€å€¼æ•°é‡ï¼ˆä»…å¯¹å‰1000è¡Œï¼Œé¿å…å†…å­˜é—®é¢˜ï¼‰
        sample_df = df.head(1000) if len(df) > 1000 else df
        for col in df.columns:
            try:
                structure_info['unique_counts'][col] = sample_df[col].nunique()
            except:
                structure_info['unique_counts'][col] = -1
        
        print(f"   æ€»åˆ—æ•°: {structure_info['total_columns']}")
        print(f"   æ€»è¡Œæ•°: {structure_info['total_rows']:,}")
        print(f"   å†…å­˜ä½¿ç”¨: {structure_info['memory_usage_mb']:.1f} MB")
        
        return structure_info
    
    def create_feature_indices(self, df: pd.DataFrame, classification: Dict[str, List]) -> Dict:
        """åˆ›å»ºç‰¹å¾ç´¢å¼•æ˜ å°„"""
        print("ğŸ“‹ åˆ›å»ºç‰¹å¾ç´¢å¼•æ˜ å°„...")
        
        categorical_features = classification['categorical_features']
        numerical_features = classification['numerical_features']
        
        # æŒ‰åŸå§‹åˆ—é¡ºåºæ’åºç‰¹å¾
        all_columns = list(df.columns)
        categorical_features = [col for col in all_columns if col in categorical_features]
        numerical_features = [col for col in all_columns if col in numerical_features]
        
        # åˆ›å»ºç´¢å¼•æ˜ å°„
        cat_idxs = list(range(len(categorical_features)))
        con_idxs = list(range(len(categorical_features), len(categorical_features) + len(numerical_features)))
        
        # è®¡ç®—ç±»åˆ«ç‰¹å¾çš„ç»´åº¦
        cat_dims = []
        for col in categorical_features:
            try:
                unique_count = df[col].nunique()
                cat_dims.append(unique_count)
            except:
                cat_dims.append(2)  # é»˜è®¤äºŒåˆ†ç±»
        
        indices = {
            'categorical_indices': cat_idxs,
            'numerical_indices': con_idxs,
            'categorical_dimensions': cat_dims,
            'categorical_features': categorical_features,
            'numerical_features': numerical_features,
            'total_features': len(categorical_features) + len(numerical_features)
        }
        
        print(f"   ç±»åˆ«ç‰¹å¾ç´¢å¼•: {len(cat_idxs)} ä¸ª")
        print(f"   æ•°å€¼ç‰¹å¾ç´¢å¼•: {len(con_idxs)} ä¸ª")
        print(f"   æ€»ç‰¹å¾æ•°: {indices['total_features']}")
        
        return indices
    
    def process_dataframe(self, df: pd.DataFrame, output_dir: str = "feature_analysis") -> Dict:
        """å¤„ç†DataFrameå¹¶ç”Ÿæˆå®Œæ•´çš„ç‰¹å¾åˆ†ææŠ¥å‘Š"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†DataFrame (è¾“å‡ºç›®å½•: {output_dir})")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ç»“æ„åˆ†æ
        structure = self.analyze_dataframe_structure(df)
        
        # 2. ç‰¹å¾åˆ†ç±»
        classification = self.classify_features_automatically(df)
        
        # 3. åˆ›å»ºç´¢å¼•
        indices = self.create_feature_indices(df, classification)
        
        # 4. ç”ŸæˆæŠ¥å‘Š
        results = {
            'structure': structure,
            'classification': classification,
            'indices': indices,
            'output_directory': output_dir
        }
        
        print(f"\nâœ… DataFrameå¤„ç†å®Œæˆ!")
        return results


def analyze_cic_iot_features(csv_file_path: str, output_dir: str = "feature_analysis") -> Dict:
    """åˆ†æCIC IoTæ•°æ®é›†ç‰¹å¾çš„ä¸»å‡½æ•°"""
    
    print(f"ğŸ“Š å¼€å§‹åˆ†æCIC IoTç‰¹å¾æ–‡ä»¶: {csv_file_path}")
    
    # åˆ›å»ºåˆ†ç±»å™¨
    classifier = CICIoTFeatureClassifier()
    
    # è¯»å–æ•°æ®æ ·æœ¬
    df_sample = pd.read_csv(csv_file_path, nrows=5000)  # åªè¯»å–å‰5000è¡Œç”¨äºåˆ†æ
    
    # å¤„ç†æ•°æ®
    results = classifier.process_dataframe(df_sample, output_dir)
    
    return results


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    csv_path = "/mnt/d/æ•°æ®é›†/CIC/BenignTraffic.csv"  # æ›¿æ¢ä¸ºæ‚¨çš„æ–‡ä»¶è·¯å¾„
    results = analyze_cic_iot_features(csv_path)
    
    print(f"\nğŸ¯ åˆ†æå®Œæˆ! ç»“æœä¿å­˜åœ¨: {results['output_directory']}") 